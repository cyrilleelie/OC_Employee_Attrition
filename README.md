---
title: API PrÃ©diction Attrition RH
emoji: ğŸ“Š
colorFrom: indigo
colorTo: green
sdk: docker
app_port: 8000
license: mit # Ou apache-2.0, etc. - Mettez la licence que vous souhaitez
---

# Projet : PrÃ©diction de l'Attrition des EmployÃ©s et API

Ce projet a pour objectif d'analyser les donnÃ©es RH afin de construire un modÃ¨le de Machine Learning capable de prÃ©dire le dÃ©part volontaire (attrition) des employÃ©s. Le modÃ¨le est ensuite exposÃ© via une API RESTful construite avec FastAPI, prÃªte Ã  Ãªtre dÃ©ployÃ©e, et les interactions avec l'API sont enregistrÃ©es dans une base de donnÃ©es PostgreSQL.

## ğŸ¯ Objectifs

* **Analyser** les facteurs clÃ©s influenÃ§ant l'attrition des employÃ©s.
* **Construire et EntraÃ®ner** un modÃ¨le de classification binaire performant.
* **DÃ©velopper une API** pour obtenir des prÃ©dictions en temps rÃ©el pour un ou plusieurs employÃ©s.
* **IntÃ©grer une base de donnÃ©es PostgreSQL** pour la gestion des donnÃ©es d'entraÃ®nement et l'enregistrement des prÃ©dictions de l'API.
* **Conteneuriser** l'application avec Docker pour un dÃ©ploiement facile de l'API.
* **DÃ©ployer** l'API sur Hugging Face Spaces.

## ğŸ› ï¸ Technologies UtilisÃ©es

* **Langage :** Python 3.12
* **Analyse & ML :** Pandas, NumPy, Scikit-learn, Joblib
* **API :** FastAPI, Uvicorn, Pydantic
* **Base de DonnÃ©es :** PostgreSQL, SQLAlchemy
* **Gestion de DÃ©pendances :** Poetry
* **Conteneurisation :** Docker, Docker Compose (pour la BDD locale)
* **DÃ©ploiement :** Hugging Face Spaces
* **CI/CD :** GitHub Actions

## ğŸ“‚ Structure du Projet

Le projet est organisÃ© de la maniÃ¨re suivante :

```text
mon_projet_attrition/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ ci.yml
â”œâ”€â”€ .gitignore
â”œâ”€â”€ .env.example
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ README.md
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ poetry.lock
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ data/
â”‚   â””â”€â”€ raw/
        â”œâ”€â”€ extrait_sirh.csv
        â”œâ”€â”€ extrait_eval.csv
â”‚       â””â”€â”€ extrait_sondage.csv
â”œâ”€â”€ models/
â”‚   â””â”€â”€ attrition_model.joblib
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ (vos notebooks ici, ex: 01_exploration.ipynb)
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ populate_employees_table.py
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”‚   â””â”€â”€ schemas.py
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ data_processing/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ load_data.py
â”‚   â”‚   â””â”€â”€ preprocess.py
â”‚   â”œâ”€â”€ database/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ database_setup.py
â”‚   â”‚   â”œâ”€â”€ init_db.py
â”‚   â”‚   â””â”€â”€ models.py
â”‚   â””â”€â”€ modeling/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ predict.py
â”‚       â””â”€â”€ train_model.py
â””â”€â”€ tests/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ functional/
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â””â”€â”€ test_api.py
    â””â”€â”€ unit/
        â”œâ”€â”€ __init__.py
        â””â”€â”€ test_preprocess.py
```

## ğŸš€ Installation et Configuration Locale

**PrÃ©requis :**

* [Git](https://git-scm.com/)
* [Python 3.12+](https://www.python.org/)
* [Poetry](https://python-poetry.org/docs/#installation) (pour la gestion des dÃ©pendances Python)
* [Docker Desktop](https://www.docker.com/products/docker-desktop/) (ou Docker Engine + Docker Compose sÃ©parÃ©ment sur Linux) pour la base de donnÃ©es PostgreSQL.

**Ã‰tapes :**

1.  **Clonez le repository :**
    ```bash
    git clone [URL_DE_VOTRE_REPO_GITHUB]
    cd mon_projet_attrition
    ```

2.  **Installez les dÃ©pendances Python avec Poetry :**
    ```bash
    poetry install
    ```
    *(Cela crÃ©era un environnement virtuel et installera toutes les dÃ©pendances listÃ©es dans `pyproject.toml`)*.

3.  **Configurez les Variables d'Environnement pour la Base de DonnÃ©es :**
    * Copiez le fichier d'exemple `.env.example` en `.env` :
        ```bash
        cp .env.example .env
        ```
    * Modifiez le fichier `.env` avec vos propres identifiants pour la base de donnÃ©es locale. Ce fichier est ignorÃ© par Git.
        ```env
        # .env - VOS SECRETS LOCAUX
        POSTGRES_USER=votre_user_pg
        POSTGRES_PASSWORD=votre_mot_de_passe_pg_solide
        POSTGRES_DB=attrition_db_dev
        DB_HOST_PORT=5432
        ```

4.  **DÃ©marrez le Service PostgreSQL avec Docker Compose :**
    Assurez-vous que Docker Desktop est en cours d'exÃ©cution.
    ```bash
    docker-compose up -d
    ```
    * Pour arrÃªter le service : `docker-compose down`
    * Pour voir les logs de la base de donnÃ©es : `docker-compose logs db`

5.  **Initialisez la Base de DonnÃ©es (CrÃ©ation des Tables) :**
    Activez d'abord l'environnement Poetry si ce n'est pas dÃ©jÃ  fait (`poetry shell`).
    ```bash
    poetry run python -m src.database.init_db
    ```

6.  **Peuplez la Table `employees` (DonnÃ©es Initiales) :**
    Ce script charge les donnÃ©es des CSV, les nettoie et les insÃ¨re dans la table `employees`.
    ```bash
    poetry run python -m scripts.populate_employees_table
    ```

7.  **Activez l'Environnement Virtuel Poetry (si pas dÃ©jÃ  fait) :**
    ```bash
    poetry shell
    ```
    *(Votre terminal est maintenant configurÃ© pour utiliser l'interprÃ©teur Python et les librairies de cet environnement).*

## ğŸ“ˆ Usage

*(Assurez-vous d'Ãªtre dans l'environnement Poetry : `poetry shell`, et que votre base de donnÃ©es PostgreSQL Docker est dÃ©marrÃ©e).*

1.  **EntraÃ®ner le modÃ¨le :**
    Le modÃ¨le sera entraÃ®nÃ© en utilisant les donnÃ©es de la table `employees` de votre base PostgreSQL.
    ```bash
    python -m src.modeling.train_model
    ```
    *(Le modÃ¨le entraÃ®nÃ© est sauvegardÃ© dans `models/`)*.

2.  **Lancer l'API FastAPI :**
    ```bash
    uvicorn src.api.main:app --reload
    ```
    *(Le serveur dÃ©marrera sur `http://127.0.0.1:8000`. `--reload` permet le redÃ©marrage automatique lors de modifications).*

## ğŸ”Œ API Endpoints

Une fois l'API lancÃ©e :

* **Documentation Interactive (Swagger UI) :** [http://127.0.0.1:8000/docs](http://127.0.0.1:8000/docs)
    * Explorez et testez les endpoints ici.
* **Health Check :** `GET /`
* **PrÃ©diction Unique :** `POST /predict`
* **PrÃ©diction en Masse :** `POST /predict_bulk`

Les appels Ã  `/predict` et `/predict_bulk` sont enregistrÃ©s dans la table `api_prediction_logs` de la base de donnÃ©es PostgreSQL.

## âœ… Tests

Pour lancer la suite de tests (unitaires et fonctionnels) :
```bash
poetry run pytest